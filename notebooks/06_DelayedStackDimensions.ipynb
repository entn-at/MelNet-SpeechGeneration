{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook's purpose is to show how the operations on the DelayedStack work, paying special attention to shapes and the correctness of the shapes transformations.\n",
    "\n",
    "# General Information\n",
    "In general we work with hidden state $h[l]$ with shape:\n",
    "* Time-delayed stack $h^t[l]$: [B, FREQ, FRAMES, HIDDEN_SIZE].\n",
    "* Frequency-delayed stack $h^f[l]$: [B, FREQ, FRAMES, HIDDEN_SIZE].\n",
    "* Centralized stack $h^c[l]$: [B, 1, FRAMES, HIDDEN_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "HIDDEN_SIZE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Layer\n",
    "\n",
    "### Time-delayed stack\n",
    "To ensure output $h^{t}_{ij}[l]$ is only a function of frames which lie in the context $x_{<ij}$, \n",
    "the inputs to the time-delayed stack are shifted backwards one step in time: $h^{t}_{ij}[0] = W^{t}_0 x_{i-1, j}$ [MelNet formula (7)].\n",
    "\n",
    "For this reason, we have to \"invent\" the first frame. In this case, we are going to assume that the first frame is all 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrogram = torch.Tensor([[[11,12,13,14],\n",
    "                             [15,16,17,18],\n",
    "                             [19,20,21,22]]])\n",
    "spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 4]),\n",
       " tensor([[[ 0., 11., 12., 13.],\n",
       "          [ 0., 15., 16., 17.],\n",
       "          [ 0., 19., 20., 21.]]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_time_pad = F.pad(spectrogram,(1,-1))  # we put -1 to maintain the number of FRAMES equal to 4 \n",
    "x_time_pad.shape, x_time_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, we could use other values like:\n",
    "* random values\n",
    "* average values of the first frame of the spectrograms in our dataset\n",
    "\n",
    "Now, we are going to implement the linear transformation [MelNet formula (7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 4, 1])\n",
      "torch.Size([1, 3, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "# First, we change shape from [B, FREQ, FRAMES] to [B, FREQ, FRAMES, 1]\n",
    "x_time_pad = x_time_pad.unsqueeze(-1)\n",
    "print(x_time_pad.shape)\n",
    "\n",
    "# Linear transformation\n",
    "W_t_0 = nn.Linear(in_features=1, out_features=HIDDEN_SIZE)\n",
    "h_t_0 = W_t_0(x_time_pad)\n",
    "print(h_t_0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see how the output shape of the hidden layer zero of the time-delayed stack corresponds to [B=1, FREQ=3, FRAMES=4, HIDDEN_SIZE=2].\n",
    "\n",
    "### Frequency-delayed stack\n",
    "To ensure output $h^{t}_{ij}[l]$ is only a function of frames which lie in the context $x_{<ij}$, \n",
    "the inputs to the time-delayed stack are shifted backwards one step along the frequency axis: $h^{f}_{ij}[0] = W^{f}_0 x_{i, j-1}$ [MelNet formula (9)].\n",
    "\n",
    "For this reason, we have to \"invent\" the \"first (lowest)\" frequency for all frames. In this case, we are going to assume that the \"first (lowest)\" frequency is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 4]),\n",
       " tensor([[[ 0.,  0.,  0.,  0.],\n",
       "          [11., 12., 13., 14.],\n",
       "          [15., 16., 17., 18.]]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_freq_pad = F.pad(spectrogram,(0,0,1,-1))  # we put -1 to maintain the number of FREQ equal to 3\n",
    "x_freq_pad.shape, x_freq_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, we could use other values like:\n",
    "* random values\n",
    "* average values of the \"first (lowest)\" frequenct of the spectrograms in our dataset\n",
    "\n",
    "Now, we are going to implement the linear transformation [MelNet formula (9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 4, 1])\n",
      "torch.Size([1, 3, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "# First, we change shape from [B, FREQ, FRAMES] to [B, FREQ, FRAMES, 1]\n",
    "x_freq_pad = x_freq_pad.unsqueeze(-1)\n",
    "print(x_freq_pad.shape)\n",
    "\n",
    "# Linear transformation\n",
    "W_f_0 = nn.Linear(in_features=1, out_features=HIDDEN_SIZE)\n",
    "h_f_0 = W_t_0(x_freq_pad)\n",
    "print(h_f_0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see how the output shape of the hidden layer zero of the frequency-delayed stack corresponds to [B=1, FREQ=3, FRAMES=4, HIDDEN_SIZE=2].\n",
    "\n",
    "## Centralized stack\n",
    "To ensure output $h^{c}_{i}[l]$ is only a function of frames which lie in the context $x_{<ij}$, \n",
    "the inputs to the time-delayed stack are shifted backwards one step along the time axis: $h^{c}_{i}[0] = W^{c}_0 x_{i-1, *}$ [MelNet formula (11)].\n",
    "\n",
    "For this reason, we have to \"invent\" the first frame. In this case, we are going to assume that the frame is all 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 4]),\n",
       " tensor([[[ 0., 11., 12., 13.],\n",
       "          [ 0., 15., 16., 17.],\n",
       "          [ 0., 19., 20., 21.]]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_central_pad = F.pad(spectrogram, (1,-1))  # we put -1 to maintain the number of FRAMES equal to 4\n",
    "x_central_pad.shape, x_central_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, we could use other values like:\n",
    "* random values\n",
    "* average values of the first frame of the spectrograms in our dataset\n",
    "\n",
    "Now, we are going to implement the linear transformation [MelNet formula (11)].\n",
    "\n",
    "The central stack, at each timestep, it takes an entire frame as input and outputs a single vector consisting of the RNN hidden state, so we have to manipulate the tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 3]),\n",
       " tensor([[[ 0.,  0.,  0.],\n",
       "          [11., 15., 19.],\n",
       "          [12., 16., 20.],\n",
       "          [13., 17., 21.]]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_central_pad = x_central_pad.transpose(1,2)\n",
    "x_central_pad.shape, x_central_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "# Linear transformation\n",
    "FREQ = 3\n",
    "W_c_0 = nn.Linear(in_features=3, out_features=HIDDEN_SIZE)\n",
    "h_c_0 = W_c_0(x_central_pad)\n",
    "h_c_0 = h_c_0.unsqueeze(dim=1)\n",
    "print(h_c_0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see how the output shape of the hidden layer zero of the centralized stack corresponds to [B=1, 1, FRAMES=4, HIDDEN_SIZE=2].\n",
    "\n",
    "# Other layers\n",
    "\n",
    "TODO: explain computations of other layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 2\n",
    "rnn_l = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
    "W_0 = nn.Linear(in_features=1, out_features=hidden_size)\n",
    "W_0_c = nn.Linear(in_features=3, out_features=hidden_size)\n",
    "W_l = nn.Linear(in_features=hidden_size, out_features=hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 4, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.Tensor([[[[10],[11],[12],[13]],\n",
    "                      [[20],[21],[22],[23]],\n",
    "                      [[30],[31],[32],[33]]],\n",
    "                     [[[40],[41],[42],[43]],\n",
    "                      [[50],[51],[52],[53]],\n",
    "                      [[60],[61],[62],[63]]]\n",
    "                    ])\n",
    "B, FREQ, FRAMES, HIDDEN_SIZE = data.size()\n",
    "B, FREQ, FRAMES, HIDDEN_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.Tensor([[[10,11,12,13],\n",
    "                      [20,21,22,23],\n",
    "                      [30,31,32,33]],\n",
    "                     [[40,41,42,43],\n",
    "                      [50,51,52,53],\n",
    "                      [60,61,62,63]]\n",
    "                    ])\n",
    "B, FREQ, FRAMES = data.size()\n",
    "B, FREQ, FRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 2])\n",
      "torch.Size([2, 4, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 4, 2]), torch.Size([2, 1, 4, 2]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = W_0(data.unsqueeze(-1))\n",
    "print(res.shape)\n",
    "print(data.transpose(1,2).shape)\n",
    "res_c = W_0_c(data.transpose(1,2))\n",
    "res_c = res_c.unsqueeze(1)\n",
    "res.shape, res_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ -1.5819, -14.4504],\n",
       "          [ -1.9500, -14.6376],\n",
       "          [ -2.3181, -14.8248],\n",
       "          [ -2.6862, -15.0120]],\n",
       "\n",
       "         [[  0.0225,  -6.4117],\n",
       "          [ -0.3455,  -6.5989],\n",
       "          [ -0.7136,  -6.7861],\n",
       "          [ -1.0817,  -6.9733]],\n",
       "\n",
       "         [[  1.6270,   1.6270],\n",
       "          [  1.2589,   1.4398],\n",
       "          [  0.8908,   1.2526],\n",
       "          [  0.5228,   1.0654]]],\n",
       "\n",
       "\n",
       "        [[[-12.6244, -20.0658],\n",
       "          [-12.9924, -20.2530],\n",
       "          [-13.3605, -20.4402],\n",
       "          [-13.7286, -20.6274]],\n",
       "\n",
       "         [[-11.0199, -12.0271],\n",
       "          [-11.3880, -12.2143],\n",
       "          [-11.7560, -12.4015],\n",
       "          [-12.1241, -12.5887]],\n",
       "\n",
       "         [[ -9.4154,  -3.9884],\n",
       "          [ -9.7835,  -4.1756],\n",
       "          [-10.1516,  -4.3628],\n",
       "          [-10.5197,  -4.5499]]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res + res_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_backwardfreq = data.transpose(1,2)\n",
    "print(data_backwardfreq.size())\n",
    "data_backwardfreq = data_backwardfreq.contiguous().view(-1, FREQ, HIDDEN_SIZE)\n",
    "print(data_backwardfreq.shape)\n",
    "data_backwardfreq = data_backwardfreq.flip(1)\n",
    "data_backwardfreq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = W_0(data_backwardfreq)\n",
    "res, hid = rnn:l(res)\n",
    "res.contiguous().view(B, FRAMES, FREQ, HIDDEN_SIZE).transpose(1,2).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
