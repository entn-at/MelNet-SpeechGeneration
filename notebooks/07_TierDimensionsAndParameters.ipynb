{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os,sys,inspect\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from src.model.DelayedStack import DelayedStackLayer0, DelayedStackLayer\n",
    "from src.model.Tier import Tier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to check that every module implemented runs correctly and its parameters are correct.\n",
    "\n",
    "First, let's initialize some general parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 2\n",
    "has_central_stack=True\n",
    "freq = 3\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrogram = torch.Tensor([[[11,12,13,14],\n",
    "                             [15,16,17,18],\n",
    "                             [19,20,21,22]]])\n",
    "spectrogram.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delayed Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer0 = DelayedStackLayer0(hidden_size=hidden_size, has_central_stack=has_central_stack, FREQ=freq)\n",
    "layer1 = DelayedStackLayer(layer=1, hidden_size=hidden_size, has_central_stack=has_central_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0's state_dict:\n",
      "W_t_0.weight \t torch.Size([2, 1])\n",
      "W_t_0.bias \t torch.Size([2])\n",
      "W_f_0.weight \t torch.Size([2, 1])\n",
      "W_f_0.bias \t torch.Size([2])\n",
      "W_c_0.weight \t torch.Size([2, 3])\n",
      "W_c_0.bias \t torch.Size([2])\n",
      "\n",
      "Layer 1's state_dict:\n",
      "rnn_t_l_forwardtime.weight_ih_l0 \t torch.Size([8, 2])\n",
      "rnn_t_l_forwardtime.weight_hh_l0 \t torch.Size([8, 2])\n",
      "rnn_t_l_forwardtime.bias_ih_l0 \t torch.Size([8])\n",
      "rnn_t_l_forwardtime.bias_hh_l0 \t torch.Size([8])\n",
      "rnn_t_l_forwardfreq.weight_ih_l0 \t torch.Size([8, 2])\n",
      "rnn_t_l_forwardfreq.weight_hh_l0 \t torch.Size([8, 2])\n",
      "rnn_t_l_forwardfreq.bias_ih_l0 \t torch.Size([8])\n",
      "rnn_t_l_forwardfreq.bias_hh_l0 \t torch.Size([8])\n",
      "rnn_t_l_backwardfreq.weight_ih_l0 \t torch.Size([8, 2])\n",
      "rnn_t_l_backwardfreq.weight_hh_l0 \t torch.Size([8, 2])\n",
      "rnn_t_l_backwardfreq.bias_ih_l0 \t torch.Size([8])\n",
      "rnn_t_l_backwardfreq.bias_hh_l0 \t torch.Size([8])\n",
      "W_t_l.weight \t torch.Size([2, 6])\n",
      "W_t_l.bias \t torch.Size([2])\n",
      "rnn_f_l.weight_ih_l0 \t torch.Size([8, 2])\n",
      "rnn_f_l.weight_hh_l0 \t torch.Size([8, 2])\n",
      "rnn_f_l.bias_ih_l0 \t torch.Size([8])\n",
      "rnn_f_l.bias_hh_l0 \t torch.Size([8])\n",
      "W_f_l.weight \t torch.Size([2, 2])\n",
      "W_f_l.bias \t torch.Size([2])\n",
      "rnn_c_l.weight_ih_l0 \t torch.Size([8, 2])\n",
      "rnn_c_l.weight_hh_l0 \t torch.Size([8, 2])\n",
      "rnn_c_l.bias_ih_l0 \t torch.Size([8])\n",
      "rnn_c_l.bias_hh_l0 \t torch.Size([8])\n",
      "W_c_l.weight \t torch.Size([2, 2])\n",
      "W_c_l.bias \t torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "#Print layer 0's state_dict\n",
    "print(\"Layer 0's state_dict:\")\n",
    "for param_tensor in layer0.state_dict():\n",
    "    print(param_tensor, \"\\t\", layer0.state_dict()[param_tensor].size())\n",
    "    \n",
    "#Print layer 1's state_dict\n",
    "print(\"\\nLayer 1's state_dict:\")\n",
    "for param_tensor in layer1.state_dict():\n",
    "    print(param_tensor, \"\\t\", layer1.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tier1 = Tier(tier=1, n_layers=3, hidden_size=hidden_size, FREQ=freq, K=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tier 1's state_dict:\n",
      "layers.0.W_t_0.weight \t torch.Size([2, 1])\n",
      "layers.0.W_t_0.bias \t torch.Size([2])\n",
      "layers.0.W_f_0.weight \t torch.Size([2, 1])\n",
      "layers.0.W_f_0.bias \t torch.Size([2])\n",
      "layers.0.W_c_0.weight \t torch.Size([2, 3])\n",
      "layers.0.W_c_0.bias \t torch.Size([2])\n",
      "layers.1.rnn_t_l_forwardtime.weight_ih_l0 \t torch.Size([8, 2])\n",
      "layers.1.rnn_t_l_forwardtime.weight_hh_l0 \t torch.Size([8, 2])\n",
      "layers.1.rnn_t_l_forwardtime.bias_ih_l0 \t torch.Size([8])\n",
      "layers.1.rnn_t_l_forwardtime.bias_hh_l0 \t torch.Size([8])\n",
      "layers.1.rnn_t_l_forwardfreq.weight_ih_l0 \t torch.Size([8, 2])\n",
      "layers.1.rnn_t_l_forwardfreq.weight_hh_l0 \t torch.Size([8, 2])\n",
      "layers.1.rnn_t_l_forwardfreq.bias_ih_l0 \t torch.Size([8])\n",
      "layers.1.rnn_t_l_forwardfreq.bias_hh_l0 \t torch.Size([8])\n",
      "layers.1.rnn_t_l_backwardfreq.weight_ih_l0 \t torch.Size([8, 2])\n",
      "layers.1.rnn_t_l_backwardfreq.weight_hh_l0 \t torch.Size([8, 2])\n",
      "layers.1.rnn_t_l_backwardfreq.bias_ih_l0 \t torch.Size([8])\n",
      "layers.1.rnn_t_l_backwardfreq.bias_hh_l0 \t torch.Size([8])\n",
      "layers.1.W_t_l.weight \t torch.Size([2, 6])\n",
      "layers.1.W_t_l.bias \t torch.Size([2])\n",
      "layers.1.rnn_f_l.weight_ih_l0 \t torch.Size([8, 2])\n",
      "layers.1.rnn_f_l.weight_hh_l0 \t torch.Size([8, 2])\n",
      "layers.1.rnn_f_l.bias_ih_l0 \t torch.Size([8])\n",
      "layers.1.rnn_f_l.bias_hh_l0 \t torch.Size([8])\n",
      "layers.1.W_f_l.weight \t torch.Size([2, 2])\n",
      "layers.1.W_f_l.bias \t torch.Size([2])\n",
      "layers.1.rnn_c_l.weight_ih_l0 \t torch.Size([8, 2])\n",
      "layers.1.rnn_c_l.weight_hh_l0 \t torch.Size([8, 2])\n",
      "layers.1.rnn_c_l.bias_ih_l0 \t torch.Size([8])\n",
      "layers.1.rnn_c_l.bias_hh_l0 \t torch.Size([8])\n",
      "layers.1.W_c_l.weight \t torch.Size([2, 2])\n",
      "layers.1.W_c_l.bias \t torch.Size([2])\n",
      "layers.2.rnn_t_l_forwardtime.weight_ih_l0 \t torch.Size([8, 2])\n",
      "layers.2.rnn_t_l_forwardtime.weight_hh_l0 \t torch.Size([8, 2])\n",
      "layers.2.rnn_t_l_forwardtime.bias_ih_l0 \t torch.Size([8])\n",
      "layers.2.rnn_t_l_forwardtime.bias_hh_l0 \t torch.Size([8])\n",
      "layers.2.rnn_t_l_forwardfreq.weight_ih_l0 \t torch.Size([8, 2])\n",
      "layers.2.rnn_t_l_forwardfreq.weight_hh_l0 \t torch.Size([8, 2])\n",
      "layers.2.rnn_t_l_forwardfreq.bias_ih_l0 \t torch.Size([8])\n",
      "layers.2.rnn_t_l_forwardfreq.bias_hh_l0 \t torch.Size([8])\n",
      "layers.2.rnn_t_l_backwardfreq.weight_ih_l0 \t torch.Size([8, 2])\n",
      "layers.2.rnn_t_l_backwardfreq.weight_hh_l0 \t torch.Size([8, 2])\n",
      "layers.2.rnn_t_l_backwardfreq.bias_ih_l0 \t torch.Size([8])\n",
      "layers.2.rnn_t_l_backwardfreq.bias_hh_l0 \t torch.Size([8])\n",
      "layers.2.W_t_l.weight \t torch.Size([2, 6])\n",
      "layers.2.W_t_l.bias \t torch.Size([2])\n",
      "layers.2.rnn_f_l.weight_ih_l0 \t torch.Size([8, 2])\n",
      "layers.2.rnn_f_l.weight_hh_l0 \t torch.Size([8, 2])\n",
      "layers.2.rnn_f_l.bias_ih_l0 \t torch.Size([8])\n",
      "layers.2.rnn_f_l.bias_hh_l0 \t torch.Size([8])\n",
      "layers.2.W_f_l.weight \t torch.Size([2, 2])\n",
      "layers.2.W_f_l.bias \t torch.Size([2])\n",
      "layers.2.rnn_c_l.weight_ih_l0 \t torch.Size([8, 2])\n",
      "layers.2.rnn_c_l.weight_hh_l0 \t torch.Size([8, 2])\n",
      "layers.2.rnn_c_l.bias_ih_l0 \t torch.Size([8])\n",
      "layers.2.rnn_c_l.bias_hh_l0 \t torch.Size([8])\n",
      "layers.2.W_c_l.weight \t torch.Size([2, 2])\n",
      "layers.2.W_c_l.bias \t torch.Size([2])\n",
      "W_theta.weight \t torch.Size([9, 2])\n",
      "W_theta.bias \t torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "#Print tier 1's state_dict\n",
    "print(\"Tier 1's state_dict:\")\n",
    "for param_tensor in tier1.state_dict():\n",
    "    print(param_tensor, \"\\t\", tier1.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 4, 3]), torch.Size([1, 3, 4, 3]), torch.Size([1, 3, 4, 3]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_hat, std_hat, pi_hat = tier1(spectrogram)\n",
    "mu_hat.shape, std_hat.shape, pi_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (pytorchtutorial)",
   "language": "python",
   "name": "pycharm-daf6d826"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
